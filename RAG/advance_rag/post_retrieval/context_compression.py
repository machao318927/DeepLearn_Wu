# ðŸ“¦ post_retrieval/context_compression.py
from transformers import pipeline
import torch


class ContextCompressor:
    def __init__(self, model_name="IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese"):
        self.device = 0 if torch.cuda.is_available() else -1
        self.summarizer = pipeline("summarization", model=model_name, device=self.device)

    def compress(self, documents, max_length=64):
        """
        å°†å¤šä¸ªæ–‡æ¡£åŽ‹ç¼©ä¸ºä¸€æ®µæ‘˜è¦ï¼ˆé€‚é…ä¸­æ–‡ï¼‰
        """
        combined = "ã€‚".join(documents)
        result = self.summarizer(combined, max_length=max_length, min_length=20, do_sample=False)
        return result[0]["summary_text"]


# âœ… æµ‹è¯•ç”¨ä¾‹
def test_context_compressor():
    print("[TEST] æ­£åœ¨æµ‹è¯• ContextCompressor")
    docs = [
        "RAG æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢ä¸Žç”Ÿæˆçš„ NLP æ¡†æž¶ã€‚",
        "RAG æ¡†æž¶å¯ä»¥æœ‰æ•ˆæå‡é—®ç­”ç³»ç»Ÿçš„æ€§èƒ½ã€‚",
        "RAG ä½¿ç”¨å‘é‡æ£€ç´¢å’Œç”Ÿæˆå¼æ¨¡åž‹ã€‚"
    ]
    compressor = ContextCompressor()
    summary = compressor.compress(docs)
    assert isinstance(summary, str) and len(summary) > 0
    print("[âœ…] Compression result:", summary)


if __name__ == "__main__":
    test_context_compressor()
