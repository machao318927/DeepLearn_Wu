{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RAG第二范式 - Advanced  RAG（朴素RAG）\n",
    "\n",
    "<img src=\"../picture/img_17.png\" width=\"50%\">\n"
   ],
   "id": "2453839e49b1b3f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. 🔷【1】User + Query\n",
    "- 这是起点，用户提出原始问题，和第一范式一样。\n",
    "\n",
    "2. 🟦【2】Pre-Retrieval（查询前处理模块）\n",
    "- ✅ 这是第二范式最显著的新增模块之一。\n",
    "\n",
    "- 目的：让“用户原始问题”变得更适合检索（提高 Recall）\n",
    "\n",
    "- 典型方法：\n",
    "\n",
    "    - Query Rewriting（查询重写）：将口语化或不清晰的问题改写为更清晰明确的检索式。例如：\"最近AI发展怎么样\" → \"2023年人工智能技术发展趋势综述\"\n",
    "\n",
    "    - Query Expansion（查询扩展）：添加同义词、相关关键词，增加召回。\n",
    "\n",
    "    - 语义结构化：将问题结构化为“主题 + 条件 + 目标”等。\n",
    "\n",
    "- 用到的模型：T5、GPT、BART、BGE-Reranker。\n",
    "\n",
    "3. 🟧【3】Documents + Indexing（文档与索引模块）\n",
    "- 作用不变：将原始知识文档切割成 chunk，然后编码成向量，用于后续的检索。\n",
    "\n",
    "- 区别点：\n",
    "\n",
    "    - 第二范式中，索引过程通常不止一个维度（比如建多个索引库：语义向量库 + BM25 关键词库）。\n",
    "\n",
    "    - 可以支持跨模态索引（如图文、图表）。\n",
    "\n",
    "4. 🟨【4】Retrieval（检索模块）\n",
    "- ✅ 这是第二范式中的“重点增强点”。\n",
    "\n",
    "- 第一范式（Naive RAG）：\n",
    "\n",
    "    - 仅使用一种向量检索模型（如 FAISS + SBERT）\n",
    "\n",
    "- 第二范式的增强：\n",
    "\n",
    "    - Hybrid Retrieval（混合检索）：同时使用 BM25（关键词）+ Dense Retrieval（语义）\n",
    "\n",
    "    - Multi-Stage Retrieval（多阶段）：\n",
    "\n",
    "        - Stage 1：用 Fast Dense Retriever 粗召回（如 DPR）\n",
    "\n",
    "        - Stage 2：用 Cross Encoder 或 reranker 精排序（如 ColBERT）\n",
    "\n",
    "- 目标：提升 召回质量 和 精确排序。\n",
    "\n",
    "5. 🟩【5】Post-Retrieval（检索后处理模块）\n",
    "- ✅ 第二范式核心中的“精炼”步骤。\n",
    "\n",
    "- 主要任务：\n",
    "\n",
    "    - Reranking：对候选文档重新排序，提高最相关 chunk 排在前面。\n",
    "\n",
    "    - Context Compression：\n",
    "\n",
    "        - 删除冗余内容，压缩上下文使其适配 LLM 输入长度限制。\n",
    "\n",
    "        - 常见方法：TF-IDF 摘句、句向量去重、信息浓缩（如 Pegasus）。\n",
    "\n",
    "6. ⚙️【6】Prompt 构造\n",
    "\n",
    "- 构建 Prompt 提交给 LLM，与第一范式一致，但质量更高、上下文更相关、token 控制更智能。\n",
    "\n",
    "7. 📩【7】Response（生成回复）\n",
    "- 由 LLM（如 GPT-4）基于 Prompt 返回答案。"
   ],
   "id": "32b8f065e4aa2fff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***总结：RAG 第二范式 = Naive RAG + 三大增强模块***\n",
    "\n",
    "|  模块   | 增强点 | 实现方式 |\n",
    "|:------:| :----: | :----: |\n",
    "|  Pre-Retrieval   | 提升检索命中率 | Query Rewriting / Expansion |\n",
    "|  Retrieval   | 提升召回质量 | DPR / Hybrid BM25+DPR / ColBERT |\n",
    "|  Post-Retrieval   | \t提升上下文精度 | Rerank / 压缩 / 去冗余 |\n",
    "\n",
    "#### 为什么第二范式比第一范式强？\n",
    "- 因为它不仅找得更准（Pre+Post优化），还能处理更大、更复杂的上下文信息（多阶段筛选），非常适合实际部署和大规模知识库环境。"
   ],
   "id": "8cb4993a416a658e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RAG 第二范式中的 Pre-Retrieval 阶段的四个模块\n",
    "|  模块名称   | 功能简述 | 是否必须 |\n",
    "|:------:| :----: | :----: |\n",
    "|  Query Rewriting   | 改写原始query使其更清晰 | ❌ 可选 |\n",
    "|  Query Expansion   | 扩展query词汇/语义，提高召回覆盖率 | ❌ 可选 |\n",
    "|  Query Classification   | 判断query类型，为路由或检索器选择提供依据 | ❌ 可选 |\n",
    "|  Query Routing   | 动态选择检索器/数据源/路径 | ✅ 推荐（如果你支持多类型检索） |\n",
    "\n",
    "模块使用与否取决于应用目标\n",
    "- ✅ 如果你只是做 FAQ 问答 / 简单文档问答：\n",
    "    - 可以 只保留 Query Routing 或不加 Pre-Retrieval 阶段，直接进入 Retriever → Generator 阶段即可。\n",
    "\n",
    "- ✅ 如果你想处理多任务、多类型输入场景：\n",
    "    - 推荐启用至少 Query Classification + Routing。\n",
    "\n",
    "- ✅ 如果你的 Query 比较短（如电商检索、短问答）：\n",
    "    - 建议加上 Query Expansion，提升召回。\n",
    "\n",
    "- ✅ 如果你的用户经常提问模糊或非结构化问题：\n",
    "    - 建议加上 Query Rewriting，提升稳定性与 clarity。"
   ],
   "id": "2892def3023fcf42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 🧠 RAG 第二范式中的 Pre-Retrieval：Query Rewriting 模块详解\n",
    "1. ✅ 一、为什么需要 Query Rewriting？\n",
    "- 在 Naive RAG 中，原始用户查询直接用于向量检索。如果查询：\n",
    "\n",
    "    - 太短、太泛化（如“最新政策”）\n",
    "\n",
    "    - 表达不明确（如“它指的是谁？”）\n",
    "\n",
    "    - 包含错别字或语法错误\n",
    "\n",
    "    - 语义跨度大（如“请总结最近 AI 与法律交叉的一些趋势”）\n",
    "\n",
    "- → 都可能导致 检索失败或检索结果质量低。\n",
    "\n",
    "- 所以，*Query Rewriting（查询重写）*模块就是用于：\n",
    "\n",
    "    - 将“用户自然语言问题”重写为“适合用于检索的查询表达”。\n",
    "\n",
    "2. 🧩 二、Query Rewriting 的核心目标\n",
    "|  目标   | 描述 |\n",
    "|:------:| :----: |\n",
    "|  语义明确   | 消除歧义，如“它”改为“ChatGPT” |\n",
    "|  内容扩展\t   | 补全背景，例如“最新进展” → “2024年4月人工智能生成内容的发展” |\n",
    "|  检索友好\t   | 适配向量检索器结构（比如使用实体化概念） |\n",
    "\n",
    "3. 🔁 三、Query Rewriting 的核心方法\n",
    "- 方法 1️⃣：基于模板的重写（Template-Based）\n",
    "- 思路：预定义常见问句模板，替换关键词\n",
    "\n",
    "- 例子：\n",
    "    - 原始：猫有什么特点？\n",
    "    - 重写：猫的物种行为、生理特征和习性有哪些？\n",
    "\n",
    "- 优点：可控、精细\n",
    "\n",
    "- 缺点：覆盖有限、不智能\n",
    "- 方法 2️⃣：基于语言模型的生成式重写（LLM-Based）\n",
    "- 思路：利用 T5、GPT 等生成模型，将原始查询翻译为“信息需求明确”的检索式\n",
    "\n",
    "- 典型模型：\n",
    "\n",
    "    - T5 + 监督训练：如 CANARD 数据集\n",
    "\n",
    "    - Prompt-Based GPT 重写：即在 Prompt 中写明重写任务，如：\n",
    "\n",
    "        - 你是搜索引擎助手，请将以下用户自然语言问题转换成更适合检索的句子：\n",
    "        - 用户问题：猫的特点是什么？\n",
    "        - 输出：\n",
    "    - Multi-turn QA 处理：对于多轮对话，通过模型补全上下文。\n",
    "- 例子（使用 GPT）：\n",
    "    - 输入：它有哪些副作用？\n",
    "    - 重写：抗VEGF蛋白药物 Earicimab 的副作用有哪些？\n",
    "- 方法 3️⃣：Embedding 扩展（Query Expansion）\n",
    "- 思路：通过同义词库或词向量找到语义相关词，拼接进查询。\n",
    "\n",
    "- 工具：WordNet、BERT、BM25+Embedding联合检索\n",
    "\n",
    "- 例子：\n",
    "    - 原始：猫的特征\n",
    "    - 扩展：猫的行为特征、生理特性、种类差异\n",
    "4. 🧱 四、Query Rewriting 的结构逻辑\n",
    "```\n",
    "【输入】：用户原始查询\n",
    "         ↓\n",
    "【Query Rewriting 模块】\n",
    "    - 上下文还原（如果是多轮）\n",
    "    - 语义补全（补背景词、主语）\n",
    "    - 表述标准化（将“它”变为明确名词）\n",
    "         ↓\n",
    "【输出】：结构清晰、语义丰富的“检索查询”\n",
    "```\n",
    "5. 🔄 五、与第一范式的核心区别\n",
    "|  模块对比   | 第一范式（Naive RAG） | 第二范式（Advanced RAG） |\n",
    "|:------:| :----: | :----: |\n",
    "|  是否预处理 Query   | ❌ 直接使用原始用户输入 | ✅ 加入智能预处理 |\n",
    "|  检索精度   | 易失败或偏离主题 | 显著提高 Recall 与精度 |\n",
    "|  对模糊查询适应性   | 差 | 好 |\n",
    "|  模型交互次数   | 少 | 多（可能用 GPT 或 T5 重写） |\n",
    "\n",
    "6. 六、研究参考与典型论文\n",
    "- 📘 \"Learning to Rewrite Queries for Conversational Search\" (SigIR 2020, CANARD)\n",
    "\n",
    "- 📘 \"Conversational Query Reformulation\" (CQR) - 用于多轮QA中的 Query Rewriting\n",
    "\n",
    "- 📘 \"FiD + DPR\" 系列模型（如 FiD-KD-Rerank）"
   ],
   "id": "a335eb92ce6d156f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### RAG 第二范式中 Pre-Retrieval 阶段的 Query Expansion（查询扩展）模块\n",
    "1. 📘 一、什么是 Query Expansion？\n",
    "- Query Expansion（查询扩展） 是指在检索前对用户原始查询语句进行增强，自动或半自动地加入一些相关词、近义词、同义短语或领域术语，以使查询表达更完整、更接近语义真值，从而提升检索到的相关文档覆盖度。\n",
    "\n",
    "2. 🔍 二、为什么需要 Query Expansion？\n",
    "- 在 RAG 第二范式中，查询内容对后续文档检索质量至关重要。Naive RAG 仅对原始 query 编码后进行向量匹配，容易错过表达不完整或语义隐含的查询。而 Query Expansion：\n",
    "\n",
    "- 可提升召回率，防止查询过于“窄”；\n",
    "\n",
    "- 弥补用户表达不清造成的信息缺失；\n",
    "\n",
    "- 与 dense retriever 配合使用（如 DPR）效果尤为显著。\n",
    "\n",
    "3. ⚙️ 三、Query Expansion 的典型方法\n",
    "- 我们可以将 Query Expansion 的方法分为以下几类：\n",
    "\n",
    "- ✅ 1. 基于知识库/同义词词典的静态扩展\n",
    "- 使用 WordNet、UMLS、Domain Ontology 等；\n",
    "\n",
    "- 将关键词扩展为其同义词、上位词、近义短语等；\n",
    "\n",
    "- 举例：\n",
    "\n",
    "    - 原始查询：“糖尿病治疗”\n",
    "\n",
    "    - 扩展后：“糖尿病治疗、胰岛素控制、血糖管理、糖尿病用药”\n",
    "\n",
    "- ✅ 2. 基于查询-文档反向索引的伪相关反馈（PRF）\n",
    "- 步骤：\n",
    "\n",
    "    - 使用原始 query 进行初步检索，得到 Top-k 初始文档；\n",
    "\n",
    "    - 提取这些文档中高频词或 TF-IDF 高的词；\n",
    "\n",
    "    - 将这些词添加回原 query 中作为扩展；\n",
    "\n",
    "- 优点：无需额外训练，灵活适应不同语料；\n",
    "\n",
    "- 缺点：对初始检索质量依赖较大。\n",
    "\n",
    "- ✅ 3. 基于语言模型的动态扩展（当前主流）\n",
    "- 使用 Encoder-Decoder 模型（如 T5、BART、GPT）；\n",
    "\n",
    "- 输入原始 query，输出语义等价或补全后的多种 query 表达；\n",
    "\n",
    "- 示例模型：\n",
    "\n",
    "    - T5 for Query Expansion：通过 finetune 让模型学会“生成更完整查询”；\n",
    "\n",
    "    - GPT for Query Brainstorming：提示词如“请为该查询扩展 3 种相关表述”。\n",
    "4. 🧪 四、实际案例（如 WikiRAG 或 REALM 中）\n",
    "- 例如用户输入 “谁设计了登月舱？”，系统可以扩展成：\n",
    "\n",
    "    - “阿波罗登月舱设计者是谁？”\n",
    "\n",
    "    - “NASA 登月计划飞船由谁制造？”\n",
    "\n",
    "    - “登月舱的设计单位和负责人是谁？”\n",
    "\n",
    "- 这些扩展语句输入 retriever 后，有更高概率命中包含答案的文档段落。"
   ],
   "id": "24c5f4923b02b914"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### RAG 第二范式中 Pre-Retrieval 阶段的 Query Classification（查询分类）模块\n",
    "\n",
    "1. 🧠 一、什么是 Query Classification？\n",
    "- Query Classification（查询分类） 是指在检索之前，对用户的查询进行意图分类 或 语义类型识别，以便：\n",
    "\n",
    "    - 路由到不同的索引集合（multi-index routing）；\n",
    "\n",
    "    - 使用不同的检索策略（如规则 vs dense retrieval）；\n",
    "\n",
    "    - 或进行更有针对性的后续处理（如多跳推理、多轮问答等）。\n",
    "\n",
    "- 这个模块的目标是让系统“理解”查询属于什么类型，从而采用最合适的处理方式，而不是一刀切的统一处理。\n",
    "\n",
    "2. 🎯 二、为什么需要 Query Classification？\n",
    "- Naive RAG 存在“查询一律平等”的问题。实际上，不同类型的查询适合不同的处理方式。例如：\n",
    "|  查询类型   | 最佳检索策略 |\n",
    "|:------:| :----: |\n",
    "|  实体查询\t   | 精确匹配索引 / 关键词 |\n",
    "|  概念解释类查询\t\t   | dense retrieval |\n",
    "|  多跳类查询\t\t   | 需要 reasoning 模块 |\n",
    "|  编程类查询\t  | 检索代码语料 + 示例 |\n",
    "- 通过查询分类，RAG 可以做以下优化：\n",
    "\n",
    "    - 选择合适的向量检索模型或策略；\n",
    "\n",
    "    - 动态选择检索参数（如top-k、embedding 模型）；\n",
    "\n",
    "    - 启动特殊 pipeline，例如多轮问答、代码分析、图谱问答等。\n",
    "3. ⚙️ 三、Query Classification 的常见方法\n",
    "- ✅ 1. 规则驱动（Rule-based）\n",
    "- 利用正则表达式、关键词表进行模式匹配；\n",
    "\n",
    "- 示例：若 query 含“是什么”、“解释”、“定义”等词，则判为“定义类查询”。\n",
    "\n",
    "- ✅ 优点：易实现、无监督\n",
    "- ⚠️ 缺点：覆盖有限、无法泛化\n",
    "\n",
    "- ✅ 2. 传统机器学习分类器（TF-IDF + SVM / XGBoost）\n",
    "- 构建标注数据集：将 query 分类为 N 类（定义类、比较类、计算类…）；\n",
    "\n",
    "- 提取文本特征（TF-IDF、POS、NER）；\n",
    "\n",
    "- 训练分类器进行识别。\n",
    "\n",
    "- ✅ 优点：解释性强、可调控\n",
    "- ⚠️ 缺点：需要人工标注样本、对语义泛化弱\n",
    "\n",
    "- ✅ 3. 基于预训练语言模型的语义分类（当前主流）\n",
    "- 使用 BERT、RoBERTa、ERNIE 等 encoder 模型；\n",
    "\n",
    "- 输入为 query，输出为类别标签；\n",
    "\n",
    "- 适合迁移学习：只需少量标注即可 fine-tune；\n",
    "\n",
    "- Huggingface 上可快速实现：\n",
    "`from transformers import BertTokenizer, BertForSequenceClassification`\n",
    "\n",
    "- ✅ 优点：语义理解好、对长查询适应强\n",
    "- ⚠️ 缺点：模型推理相对慢\n",
    "\n",
    "4. 💡 四、Query Classification 的用途和分支点\n",
    "- 在 RAG 中，一旦识别出 query 类型，可以：\n",
    "|  查询类型   | 行为调整 |\n",
    "|:------:| :----: |\n",
    "|  事实性问题\t   | 调用 dense 检索器（如 DPR） |\n",
    "|  实体精确查找  | 调用关键词倒排索引（如 BM25） |\n",
    "|  多跳类查询\t\t   | 触发 multi-hop reasoning 组件 |\n",
    "|  冷门领域专业词\t  | 走 domain-specific 索引 |\n",
    "|  情感/主观问题\t  | 调整 Prompt 风格或 LLM 回复策略 |\n",
    "- 也可以通过 query classification 决定是否需要：\n",
    "\n",
    "    - 使用 query rewriting\n",
    "\n",
    "    - 使用 query expansion\n",
    "\n",
    "    - 使用多个 retriever 并融合结果（Hybrid Retrieval）\n",
    "5. 🧪 示例：Fine-tune 一个小型 BERT 分类器\n",
    "- 比如，你想把查询分为如下四类：\n",
    "\n",
    "    - definition：解释/定义型\n",
    "\n",
    "    - comparison：比较类\n",
    "\n",
    "    - fact：事实型\n",
    "\n",
    "    - reasoning：多跳推理类\n",
    "\n",
    "\n",
    "- 你可以构造一组小样本：\n",
    "```\n",
    "samples = [\n",
    "    (\"什么是人工智能？\", \"definition\"),\n",
    "    (\"苹果和三星哪个更好？\", \"comparison\"),\n",
    "    (\"中国的首都是哪里？\", \"fact\"),\n",
    "    (\"如果火车晚点，我怎么才能按时到达？\", \"reasoning\"),\n",
    "]\n",
    "```\n",
    "- 用 BERT 进行微调后，未来所有用户 query 都可先判别类型，然后走不同的 RAG 路径。"
   ],
   "id": "d667c5a3a016777f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "####  RAG 第二范式中 Pre-Retrieval 阶段的最后一个模块：Query Routing（查询路由）\n",
    "1. 🧠 一、什么是 Query Routing（查询路由）？\n",
    "- Query Routing（查询路由） 指的是：\n",
    "\n",
    "    - 根据用户查询的类型或语义特征，将其引导到最适合的检索路径或知识源中。\n",
    "\n",
    "- 在 Naive RAG 中，所有查询都默认走一条“统一的 Dense 检索通道”，这在面对复杂、异构或多任务查询时效率低下。Query Routing 就是为了解决这个问题，让系统“按需分流”。\n",
    "\n",
    "2. 🧩 二、Query Routing 的典型目标\n",
    "- 选择不同类型的检索器（Retriever）\n",
    "\n",
    "    - 比如针对事实型问题使用 Dense Retriever（如 DPR/BGE）；\n",
    "\n",
    "    - 针对术语查找使用 BM25 倒排索引；\n",
    "\n",
    "    - 针对图谱问答使用 SPARQL 或知识图谱接口。\n",
    "\n",
    "- 选择合适的文档来源或索引库\n",
    "\n",
    "    - 比如法律类查询走法条索引，医学类查询走医学库。\n",
    "\n",
    "- 动态配置检索参数\n",
    "\n",
    "    - 如 top-k 值、embedding 模型、是否开启 query expansion 等。\n",
    "\n",
    "- 激活不同的后处理流程（如 Multi-hop Reasoning）\n",
    "\n",
    "3. 📍 三、Query Routing 的工作流程\n",
    "- 可以用以下结构表示整个 Query Routing 流程：\n",
    "```\n",
    "            ┌─────────────┐\n",
    "            │ 用户原始查询 │\n",
    "            └────┬────────┘\n",
    "                 ↓\n",
    "         ┌──────────────┐\n",
    "         │ Query Classification │ ←（前置模块）\n",
    "         └────┬────────────┘\n",
    "              ↓\n",
    "     ┌────────────────────┐\n",
    "     │ Routing Decision Unit │ ← 核心模块\n",
    "     └────┬────────────┬───┘\n",
    "          ↓            ↓\n",
    "  ┌────────────┐ ┌────────────┐\n",
    "  │ DenseIndex │ │ SparseIndex│ ← 多路检索器\n",
    "  └────────────┘ └────────────┘\n",
    "          ↓            ↓\n",
    "       合并/融合 ← （可选 Hybrid Routing）\n",
    "          ↓\n",
    "       下游 LLM\n",
    "\n",
    "```\n",
    "\n",
    "4. 🔧 四、Query Routing 的实现方式\n",
    "- ✅ 1. 基于 Query 分类的路由（最常见）\n",
    "- 根据前一步的 Query Classification 结果，将 query 分流：\n",
    "```\n",
    "if query_type == \"definition\":\n",
    "    use_dense_retriever()\n",
    "elif query_type == \"exact_match\":\n",
    "    use_sparse_retriever()\n",
    "elif query_type == \"multi-hop\":\n",
    "    route_to_multi_hop_reasoner()\n",
    "```\n",
    "- ✅ 2. 基于置信度的路由\n",
    "- 某些查询在 dense 检索中返回得分低、置信不足，则自动 fallback：\n",
    "```\n",
    "if dense_score < threshold:\n",
    "    fallback_to_BM25()\n",
    "```\n",
    "- ✅ 3. 基于 Hybrid 检索融合（RAG-Hybrid）\n",
    "- 并行调用多种检索器，融合结果（如 FAISS + BM25 + GraphRAG）：\n",
    "```\n",
    "dense_results = dense_retrieve(query)\n",
    "bm25_results = sparse_retrieve(query)\n",
    "merged = merge(dense_results, bm25_results, strategy=\"reciprocal_rank_fusion\")\n",
    "```\n",
    "5. 🧠 五、Query Routing 的设计策略与分支点\n",
    "|  决策点   | 可能策略 |\n",
    "|:------:| :----: |\n",
    "|  是否 Query Classification 后再 Routing？ | 是：更精准； 否：根据 embedding 特征直接路由 |\n",
    "|  路由依据 | 分类标签、实体检测、score 区间、领域类型等 |\n",
    "|  路由方式 | 单路静态、规则路由、动态路径规划、Multi-retriever |"
   ],
   "id": "4644b52551810d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 🎯 一、RAG 第二范式 中 Retrieval 阶段\n",
    "我们可以将其拆解为以下几类机制：\n",
    "|  模块名称   | 功能说明 |\n",
    "|:------:| :----: |\n",
    "| Document Indexing | 构建知识库的索引结构：稀疏（BM25）、稠密（向量库）、混合 |\n",
    "| Retrieval | 通过 query 获取初始 top-k 文档 |\n",
    "| Re-ranking | 使用更精确的模型对检索结果重新排序，例如 cross-encoder |\n",
    "| Filtering | 对内容进行去重、置信度过滤或格式标准化等 |"
   ],
   "id": "2148b9b9cbced494"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### 🧩 二、Retrieval 阶段的主要方法详细讲解\n",
    "1. 🔶 1. Document Indexing（文档索引构建）\n",
    "- ✅ 原理\n",
    "    - 将原始知识库（文本集合）转化为可快速检索的结构体，比如倒排索引或向量库。\n",
    "\n",
    "- ✅ 常见类型\n",
    "    - 稀疏索引（Sparse Indexing）：如 BM25/TF-IDF，基于词项频率的倒排索引\n",
    "\n",
    "    - 稠密索引（Dense Indexing）：如 FAISS、Milvus，使用向量化后的嵌入表示文档\n",
    "\n",
    "    - 混合索引（Hybrid Indexing）：将稀疏与稠密索引结合，兼具关键词匹配与语义理解能力\n",
    "\n",
    "- ✅ 作用\n",
    "    - 文档索引是整个 RAG 检索流程的**“搜索引擎后端”**，决定了后续 Retrieval 模块能否快速有效召回候选文档。\n",
    "\n",
    "2. 🔶 2. Retrieval（文档初检召回）\n",
    "- ✅ 原理\n",
    "    - 根据 Query，查询前面构建的索引，返回 top-k 个与之最相关的文档段（chunk）。\n",
    "\n",
    "- ✅ 方法\n",
    "    - 对于稀疏索引：通过关键词匹配（BM25）\n",
    "\n",
    "    - 对于稠密索引：将 query 编码成向量 → 计算与文档向量之间的余弦相似度/L2 距离 → 返回 top-k\n",
    "\n",
    "- 查询向量计算方法：\n",
    "\n",
    "    - 使用 BERT/SBERT\n",
    "\n",
    "    - 使用 Dual Encoder（query 与 doc 用不同 encoder）\n",
    "\n",
    "- ✅ 作用\n",
    "    - 负责在海量文档中筛选出前 N 个最可能相关的文档。这一步的 recall rate（召回率）越高，后续回答就越可能准确。\n",
    "\n",
    "3. 🔶 3. Re-ranking（精排）\n",
    "- ✅ 原理\n",
    "    - 对 Retrieval 返回的 top-k 候选文档重新打分排序，提升相关性精度。\n",
    "\n",
    "- ✅ 方法\n",
    "    - 使用更强大的语义模型进行句对评分，例如：\n",
    "\n",
    "        - Cross-Encoder（BERT-like）：对每个 “query + doc” 输入一次模型 → 得到相似度\n",
    "\n",
    "        - Gated Matching、ColBERT 等轻量模型\n",
    "\n",
    "    - 使用融合打分策略（score fusion）：稀疏与稠密检索的加权平均\n",
    "\n",
    "- ✅ 作用\n",
    "    - 过滤掉相关性较低的候选文档，提高最终用于生成的文档质量，从而提升整体答案的准确率和可靠性。\n",
    "\n",
    "4. 🔶 4. Filtering（后过滤）\n",
    "- ✅ 原理\n",
    "    - 在 Re-ranking 后对文档结果进行去噪和标准化，确保最终输入 LLM 的文档是“干净的、有用的”。\n",
    "\n",
    "- ✅ 方法\n",
    "    - 去重（Remove Duplicates）：避免文档重复影响生成结果\n",
    "\n",
    "    - 格式过滤（Structure Filtering）：移除无结构、乱码、超短片段等\n",
    "\n",
    "    - 置信度过滤（Confidence Filtering）：只保留打分高于阈值的文档\n",
    "\n",
    "    - 领域过滤（Domain Filtering）：如果是多知识域，可做 Query→文档领域对齐\n",
    "\n",
    "- ✅ 作用\n",
    "    - 作为文档流入生成模型的“最后一道防线”，确保上下文有信息量、无冗余、无噪声，从而提升回答质量和稳定性。\n",
    "\n",
    "\n",
    "### 🔄 三、与第一范式的核心区别？\n",
    "|  项目   |        第一范式（Naive RAG）        | 第二范式（Advanced RAG） |\n",
    "|:------:|:-----------------------------:| :----: |\n",
    "|  向量检索方式  | 单一向量检索（Sentence-BERT + FAISS） | 多模态混合（BM25 + dense + reranker） |\n",
    "|  检索粒度   |             单阶段召回             | 多阶段（召回 + 精排） |\n",
    "|  检索行为智能性   |         静态检索器（预训练向量）          | \t可训练检索器（动态优化） |\n",
    "|  是否支持复杂问题   |            一跳问题居多             | 多跳、复杂问题支持更好 |\n",
    "|  查询适应能力   |          Query 直接用            | 结合 Pre-Retrieval 阶段适配后的查询策略 |\n",
    "\n",
    "#### RAG 第二范式中的 Retrieval 阶段不再是“简单召回 top-k”，而是变成了一个可自适应、可训练、支持多模态和多阶段的智能检索系统，显著增强了对复杂问题的处理能力"
   ],
   "id": "e1a55f681481f52d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RAG 第二范式 Post-Retrieval（后检索）阶段\n",
    "- 是连接检索与生成的“桥梁”，承担着对检索结果进行结构化理解、信息融合与上下文适配的任务，确保知识能够被语言模型更准确、更自然地吸收和利用。\n",
    "\n",
    "- 这一阶段是在第一范式“简单拼接 top-k 文本”的基础上进行增强处理，其目标是：\n",
    "\n",
    "    - ✨ 构建更有效的 Prompt，使语言模型生成结果更加准确、连贯、有根据。\n",
    "- 🎯 Post-Retrieval 阶段的关键模块概览\n",
    "|  模块名称   | 功能作用 |\n",
    "|:------:| :----: |\n",
    "| Reranking | 对从检索器返回的 Top-k 文档进行 更精细的语义排序，提高最终选中文档与用户问题的匹配度。 |\n",
    "| Context Compression（上下文压缩） | 对冗长的检索结果进行摘要或提取，保留与查询最相关的信息，减少输入长度，避免超过生成模型的最大输入限制。 |\n",
    "| Context Rewriting（上下文重写） | 对检索到的文本进行改写，统一语言风格，消除歧义，使内容更易于生成模型理解。 |\n",
    "| Context Re-ranking（上下文重排序） | 根据与查询的相关性，对多个文档片段进行重新排序，确保最相关的信息优先被处理 |\n",
    "| Context Fusion（上下文融合）\t| 将多个文档片段整合成连贯的上下文，构建结构化的输入，以提高生成质量。 |\n",
    "| Filtering（筛选过滤）\t| 移除无关、重复或格式异常的段落，保证输入质量。 |\n",
    "| Evidence Aggregation（证据聚合）| 将多个文段中的信息整合为一条连贯的证据链，支持复杂逻辑推理。|\n",
    "| Answer Highlighting（答案高亮）| 将检索文段中的关键答案句、短语进行 高亮/显式标注，增强可解释性或作为引导提示。|\n",
    "\n",
    "#### 🧩 模块详解与作用逻辑\n",
    "\n",
    "1. 1️⃣ 重排序（Reranking）\n",
    "- 核心作用：对从检索器返回的 Top-k 文档进行 更精细的语义排序，提高最终选中文档与用户问题的匹配度。\n",
    "\n",
    "- 原理：使用双塔模型（如 bi-encoder）初步召回，然后用 Cross-Encoder 或融合注意力模型，对每个文档和查询对进行重新打分。\n",
    "\n",
    "- 常见模型：cross-encoder/ms-marco-MiniLM-L-6-v2、BERT-Ranker、MonoT5 等。\n",
    "\n",
    "- 适用场景：\n",
    "\n",
    "    - 检索器召回的结果中干扰信息多。\n",
    "\n",
    "    - 用户 query 比较模糊。\n",
    "\n",
    "- 不适用场景：\n",
    "\n",
    "    - 检索器（如 dense retrieval + fine-tuning）效果已经很好。\n",
    "\n",
    "- 与第一范式区别：\n",
    "\n",
    "    - 第一范式一般不涉及精细 reranking，仅靠向量相似度排序。\n",
    "\n",
    "\n",
    "\n",
    "2. 🔹 模块一：Context Compression（上下文压缩）\n",
    "- 🔧 做什么？\n",
    "    - 对检索到的多个文档片段（Chunks）进行精简处理，只保留与用户问题相关性高的部分或使用摘要进行内容浓缩。\n",
    "\n",
    "- 🔍 为什么要这么做？\n",
    "    - 大模型存在输入长度限制（token限制），不能直接塞入过多原文\n",
    "\n",
    "    - 检索到的内容可能冗余或无关\n",
    "\n",
    "    - 压缩后可提升模型生成质量，降低成本\n",
    "\n",
    "- 🛠️ 实现方式：\n",
    "    - 使用 Embedding 相关度打分，只保留最相关句子\n",
    "\n",
    "    - 使用摘要模型（如 BART、Pegasus）对长文段做 query-aware 摘要\n",
    "\n",
    "    - 使用 token budgeting 策略做预算控制（如 LightRAG）\n",
    "\n",
    "- 🔄 和检索阶段的衔接？\n",
    "    - 它是对“粗检”文档进行“精剪”，是 Retrieval 阶段的自然收尾步骤。\n",
    "\n",
    "3. 🔹 模块二：Context Rewriting（上下文重写）\n",
    "- 🔧 做什么？\n",
    "    - 对检索回来的原始片段进行 语言重写、清洗、结构优化，让其更适合被大模型理解。\n",
    "\n",
    "- 🔍 为什么要这么做？\n",
    "    - 原始文本可能是网页截取、PDF段落、带HTML符号的内容，不利于理解\n",
    "\n",
    "    - 语言风格不统一会影响模型回答准确性\n",
    "\n",
    "    - 可以借助 LLM 清洗上下文结构，使输入更加 简洁、连贯\n",
    "\n",
    "- 🛠️ 实现方式：\n",
    "    - 使用指令式 LLM 模型进行结构化改写（例如：“请将以下段落简化为学术风格描述...”）\n",
    "\n",
    "    - 可以做一些标准化操作，如去除引用格式、统一语言风格\n",
    "\n",
    "- 🎯 结果：\n",
    "    - 得到的文段更 结构清晰、语言统一，提升了输入的一致性。\n",
    "\n",
    "4. 🔹 模块三：Context Re-ranking（上下文重排序）\n",
    "- 🔧 做什么？\n",
    "    - 对多个检索结果根据与用户问题的相关性重新排序，确保最相关内容排前面。\n",
    "\n",
    "- 🔍 为什么要这么做？\n",
    "    - 检索模型（如 FAISS、BM25）是浅层匹配，相关性可能不准\n",
    "\n",
    "    - 排名前的内容对生成的影响最大（尤其是在长上下文中）\n",
    "\n",
    "- 🛠️ 实现方式：\n",
    "    - 使用 Cross-Encoder 或 BERT-Reranker 模型对每个文档和问题的对拼进行打分\n",
    "\n",
    "    - 排序后只保留前 N 个，或按权重组织上下文结构\n",
    "\n",
    "- 📘 示例方法：\n",
    "    - ColBERT\n",
    "\n",
    "    - SPLADE-RAG\n",
    "\n",
    "    - Sentence-BERT + CrossEncoder 组合\n",
    "\n",
    "5. 🔹 模块四：Context Fusion（上下文融合）\n",
    "- 🔧 做什么？\n",
    "    - 将多个上下文片段融合成一个连贯的上下文输入，供大模型作为 prompt。\n",
    "\n",
    "- 🔍 为什么要这么做？\n",
    "    - LLM 输入是线性文本，需要将多个文档融合成一个序列\n",
    "\n",
    "    - 不同来源的文档风格不一致，融合时要考虑 连接方式、去重、逻辑顺序\n",
    "\n",
    "- 🛠️ 实现方式：\n",
    "    - 简单拼接（加标记如【文档1】、【文档2】）\n",
    "\n",
    "    - 分段式构造（每段前标任务，提示其用途）\n",
    "\n",
    "    - 多文档合并再 summary 融合\n",
    "\n",
    "- 📌 融合策略：\n",
    "    - Query-aware 融合：只融合问题相关部分\n",
    "\n",
    "    - 多文档摘要融合：通过 LLM 汇总多个段落\n",
    "6. 5️⃣ 筛选过滤（Filtering）\n",
    "- 核心作用：移除无关、重复或格式异常的段落，保证输入质量。\n",
    "\n",
    "- 原理：通过规则或模型判断文本是否冗余/噪声/低质量（如 OCR 错误片段）。\n",
    "\n",
    "- 示例：\n",
    "\n",
    "    - 正则匹配 URL、乱码；\n",
    "\n",
    "    - BERT 分类器判断是否与 Query 有关。\n",
    "\n",
    "- 适用场景：\n",
    "\n",
    "    - 使用开放式搜索引擎（如 Bing、Web Search）时。\n",
    "\n",
    "- 不适用场景：\n",
    "\n",
    "    - 使用结构化、已清洗的企业文档库时。\n",
    "\n",
    "- 与第一范式区别：\n",
    "\n",
    "    - 第一范式通常信任 retriever，不额外做清洗。\n",
    "7. 6️⃣ 证据聚合（Evidence Aggregation）\n",
    "- 核心作用：将多个文段中的信息整合为一条连贯的证据链，支持复杂逻辑推理。\n",
    "\n",
    "- 原理：\n",
    "\n",
    "    - 对多个段落抽取出相关实体/因果链/时间线，再组合。\n",
    "\n",
    "    - 可使用 GraphQA、Retriever-Augmented Generation for Multi-hop QA 等模型。\n",
    "\n",
    "- 适用场景：\n",
    "\n",
    "    - 多跳问答（Who is X’s mentor’s student?）\n",
    "\n",
    "    - 法律、医疗、科研问答等复杂知识链场景。\n",
    "\n",
    "- 与第一范式区别：\n",
    "\n",
    "    - 第一范式只能进行浅层组合，不具备推理能力。\n",
    "\n",
    "8 .8️⃣ 答案高亮（Answer Highlighting）\n",
    "- 核心作用：将检索文段中的关键答案句、短语进行 高亮/显式标注，增强可解释性或作为引导提示。\n",
    "\n",
    "- 原理：\n",
    "\n",
    "    - 用关键词匹配或 span extraction 模型（如 QA-BERT）找到关键答案；\n",
    "\n",
    "    - 用 >>标注<<、粗体等方式在 Prompt 中高亮。\n",
    "\n",
    "- 适用场景：\n",
    "\n",
    "    - 需要人类阅读对齐内容（如 PDF 标注、可视化问答系统）；\n",
    "\n",
    "    - 帮助 LLM 快速聚焦回答区域。\n",
    "\n",
    "- 与第一范式区别：\n",
    "\n",
    "    - 第一范式不会引导模型“关注哪一句”，是盲读。\n",
    "\n",
    "#### 🔄 与第一范式的关键区别\n",
    "### 🔍 RAG 第一范式 vs 第二范式：Post-Retrieval 阶段关键区别\n",
    "\n",
    "| 比较维度           | 第一范式（Naive RAG）                         | 第二范式（Advanced RAG）                                  | 区别说明                                                     |\n",
    "|--------------------|----------------------------------------------|-------------------------------------------------------------|--------------------------------------------------------------|\n",
    "| 处理策略           | 不处理，检索结果直接拼接                    | 对检索结果进行压缩、重排、融合、改写等加工                | 是否“加工”检索内容，是两者本质区别                          |\n",
    "| 上下文压缩         | ❌ 无                                         | ✅ 有（如摘要提取、关键句选择）                            | 控制token长度，提升有效信息密度                             |\n",
    "| 上下文重排序       | ❌ 无                                         | ✅ 有（使用Cross-Encoder或排序模型）                      | 提升相关信息在生成中的优先级                               |\n",
    "| 上下文融合         | ❌ 无                                         | ✅ 有（合并多个段落为统一上下文）                          | 提升上下文逻辑连贯性                                       |\n",
    "| 上下文改写         | ❌ 无                                         | ✅ 有（用语言模型改写检索结果）                            | 使检索内容风格一致，适配生成需求                           |\n",
    "| Prompt 构造方式    | 拼接原文档                                   | 拼接优化后的摘要/融合结果                                  | 提高语言模型对prompt的理解能力                             |\n",
    "| 对Retriever依赖性 | 高，检索结果质量直接影响输出                | 低，可通过优化弱化无关文档影响                            | 更鲁棒，对错误检索容错性更强                               |\n",
    "| 生成准确率         | 一般，易受冗余/冲突上下文影响               | 更高，输入信息经过筛选与压缩                             | 增强生成对目标问题的聚焦能力                               |\n",
    "| 适用场景           | 快速原型、轻量场景                           | 精度要求高、跨域复杂问答系统                              | 二者在不同成本与精度需求下取舍                             |\n",
    "\n",
    "\n",
    "#### RAG 第二范式中的 Post-Retrieval 阶段不只是“拼接文档”，而是对检索结果进行理解、组织与结构化处理，最终构造一个逻辑清晰、任务明确、信息准确的 Prompt，从而显著提升语言模型生成质量与可控性。\n",
    "\n",
    "| 模块名称                | 是否必须 | 主要作用                                                         | 适用场景                                                                 |\n",
    "|-------------------------|----------|------------------------------------------------------------------|--------------------------------------------------------------------------|\n",
    "| 重排序 Reranking         | ❌ 否     | 使用 Cross-Encoder 或打分模型对 Top-k 检索结果重新排序           | 检索器性能有限，或存在冗余、不相关文段时                                 |\n",
    "| 上下文压缩 Compression    | ❌ 否     | 选择最相关片段，提取关键句，减少输入 Token 长度                  | 召回冗余多、LLM 输入限制或回答需精准时                                   |\n",
    "| 上下文融合 Fusion         | ❌ 否     | 将多个检索结果融合为统一上下文（例如多段合成摘要）               | 回答需要整合多个片段（如多跳问答、摘要、报告类输出）                    |\n",
    "| 上下文改写 Rewriting      | ❌ 否     | 改写文档片段，使其语义统一、风格一致、逻辑更连贯                 | 文档风格混杂，结构性不强，或 LLM 对原文理解不佳时                        |\n",
    "| 筛选过滤 Filtering        | ❌ 否     | 对不相关、噪声或低质量文档进行过滤处理                           | Web 检索、开源数据源中噪声较多时                                         |\n",
    "| 证据聚合 Evidence Aggregation | ❌ 否     | 多个片段联合支撑复杂问答，形成推理链                              | 多跳问答、因果关系推理、科学问答等需要综合多个证据的任务                |\n",
    "| 答案高亮 Answer Highlighting | ❌ 否     | 预标答案位置，便于人类阅读/解释或提供更强引导                     | 面向用户展示/解释，或增强生成式问答一致性（例如 PDF/网页问答）          |\n",
    "\n",
    "- 在实际实现中建议根据下列目标动态选择：\n",
    "\n",
    "    - ✅ 精准回答 → Reranking + Compression\n",
    "\n",
    "    - ✅ 多段融合 → Fusion + Aggregation\n",
    "\n",
    "    - ✅ 复杂推理 → Rewriting + Aggregation\n",
    "\n",
    "    - ✅ 对用户友好展示 → Highlighting + Rewriting\n",
    "\n",
    "    - ✅ 清洗原始搜索结果 → Filtering\n"
   ],
   "id": "c0e0783f4884279a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## RAG搭建\n",
    "- ✅ 文件结构总览\n",
    "# ✅ RAG 第二范式完整实现推荐文件结构\n",
    "```\n",
    "rag_v2_project/\n",
    "├── indexing/                        # 📦 构建向量索引（先验阶段）\n",
    "│   ├── document_splitter.py        # 文本分块器模块（支持 chunk size, overlap）\n",
    "│   ├── embedding_generator.py      # 文本向量化模块（支持多模型）\n",
    "│   ├── index_builder.py            # 构建稠密 / 稀疏 / 混合索引\n",
    "│   ├── index_saver_loader.py       # 索引保存与加载逻辑\n",
    "│   └── test_indexing.py            # 单元测试用例\n",
    "│\n",
    "├── pre_retrieval/                  # 🔁 检索前阶段（Query处理）\n",
    "│   ├── query_rewriting.py          # Query Rewriting（语义重写）\n",
    "│   ├── query_expansion.py          # Query Expansion（近义扩展）\n",
    "│   ├── query_classification.py     # Query Classification（分类路由）\n",
    "│   ├── query_routing.py            # Query Routing（路由目标检索器）\n",
    "│   └── test_pre_retrieval.py       # 单元测试\n",
    "│\n",
    "├── retrieval/                      # 🔍 检索阶段\n",
    "│   ├── dense_retriever.py          # 基于向量相似度的稠密检索器（如 Faiss）\n",
    "│   ├── sparse_retriever.py         # 稀疏检索（如 BM25）\n",
    "│   ├── hybrid_retriever.py         # 混合检索逻辑（稠密 + 稀疏融合）\n",
    "│   ├── retriever_router.py         # 检索器选择与融合接口\n",
    "│   └── test_retrieval.py           # 单元测试\n",
    "│\n",
    "├── post_retrieval/                 # 🔧 检索后优化阶段\n",
    "│   ├── context_compression.py      # 上下文压缩（摘要/去冗）\n",
    "│   ├── context_reranking.py        # Cross-Encoder 重排序模块\n",
    "│   ├── context_fusion.py           # 逻辑拼接/多跳融合\n",
    "│   ├── context_rewriting.py        # 上下文风格/语义改写\n",
    "│   └── test_post_retrieval.py      # 单元测试\n",
    "│\n",
    "├── generation/                    # 🧠 大模型生成阶段\n",
    "│   ├── prompt_builder.py           # 构造统一的 Prompt 格式\n",
    "│   ├── llm_interface.py            # 接入 OpenAI, Claude, ChatGLM 等模型\n",
    "│   ├── response_parser.py          # 提取、验证、解释生成内容\n",
    "│   └── test_generation.py          # 单元测试\n",
    "│\n",
    "├── pipeline/                      # 🧪 总控管道，集成全流程调用\n",
    "│   ├── rag_pipeline.py             # 主流程调用类（集成所有模块）\n",
    "│   └── test_pipeline.py            # 流程级测试\n",
    "│\n",
    "├── utils/                         # 🧰 通用工具函数\n",
    "│   ├── config.py                   # 超参数与路径配置\n",
    "│   ├── logging_utils.py            # 日志打印与保存\n",
    "│   └── evaluation_metrics.py       # 支持 EM, BLEU, Rouge 等指标\n",
    "│\n",
    "├── scripts/                       # 🔧 CLI & 启动脚本\n",
    "│   ├── build_index.py              # 单独构建索引\n",
    "│   ├── run_pipeline.py             # 主流程调用脚本\n",
    "│   └── demo_query.py               # 测试交互入口\n",
    "│\n",
    "└── data/                          # 📁 存放原始文档与索引文件\n",
    "    ├── raw_docs/                   # 原始知识文件夹\n",
    "    ├── vector_store/               # Faiss/Elasticsearch索引存储\n",
    "    └── logs/                       # 流程运行日志\n",
    "```"
   ],
   "id": "56a79145df2810b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "381c4f14e4392d8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
